# wordle_meta

### Using basics of Information Theory on the quest to find the best [Worlde](https://www.powerlanguage.co.uk/wordle/) starting word

# General Idea

For each word, the Relative Information Increase(RII) is defined as average uncertainty decrease for every possible "Secret" word that is being guessed, i.e.:

Testing word "apple" on the dataset ["puppy", "apple", "soapy", "poppy", "roses"] 

| Tested Word | Secret | Match | Dataset Count Before | Dataset After
|---   |---	   | ---  	| ---	| ---	|
Apple  | Apple | 游릴游릴游릴游릴游릴 | 5 | 1 
Apple  | Poppy | 游린游릳游릴游린游린 | 5 | 2 ("Puppy", "Poppy")
Apple  | Puppy | 游린游릳游릴游린游린 | 5 | 2 ("Puppy", "Poppy")
Apple  | Soapy | 游릳游릳游린游린游린 | 5 | 1
Apple  | Roses | 游린游린游린游린游릳 | 5 | 1

The average entropy decrease is thus 

`1/5 * (log2(5/1) + log2(5/2) + log2(5/2) + log2(5/1) + log2(5/1))   ~= 1.92 in (abstract binary information units) `



## Results so far:

| Word | RII |
|---   |---	|


[Full Results](https://github.com/DenysKlochkov/wordle_meta/blob/main/results/entropies-sorted.txt)

## Dataset Used

[word-list-json](https://www.npmjs.com/package/word-list-json) - Filtered 12595 5-letter Words

## More To Come:
 - Webpage Interface
 - Visualization
 - More efficient sub-sampling algorithms 
 - Word Combinations
